{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t29woLVqstOf"
      },
      "source": [
        "# EyeFormer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qkOH_v4stOg"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq ruamel.yaml"
      ],
      "metadata": {
        "id": "3Sdf35adtNi2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "btSItrlhstOg"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import ruamel.yaml as yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "import csv\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4_aTEuwstOg"
      },
      "source": [
        "Clone Eyeformer & Create the environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit==11.0\n",
        "!pip install opencv-python==4.5.3.56 Pillow einops multimatch-gaze\n",
        "!pip install transformers==4.8.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkZHo55qvCaZ",
        "outputId": "033795d0-8623-4f51-d87e-e93b04e044c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch==1.7.1 (from versions: 0.1.2, 1.0.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch==1.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting opencv-python==4.5.3.56\n",
            "  Using cached opencv-python-4.5.3.56.tar.gz (89.2 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SxZn6IMstOg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/YueJiang-nj/EyeFormer-UIST2024.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EyeFormer-UIST2024"
      ],
      "metadata": {
        "id": "QF3YyyUUuftA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **NOTE**\n",
        "\n",
        "Please change the `eval_image_root` string in `configs/Tracking.yaml` to your eval image dir"
      ],
      "metadata": {
        "id": "mYjiRznmxLtj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh40dex3stOh"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "url = 'https://drive.google.com/drive/folders/1eae63VRBfQ9XAYj3k2q2N9xDtLmSqQg_'\n",
        "gdown.download_folder(url, quiet=True)\n",
        "!mv scanpath_prediction_population_rl/ weights/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm==0.4.9"
      ],
      "metadata": {
        "id": "zY4wii6lv0yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJY2ladlstOh"
      },
      "outputs": [],
      "source": [
        "from models.model_tracking import TrackingTransformer\n",
        "from models.vit import interpolate_pos_embed\n",
        "\n",
        "import utils\n",
        "from dataset import create_dataset, create_sampler, create_loader\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFrOM84ustOh"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXu75aZPstOh"
      },
      "outputs": [],
      "source": [
        "def test(model, data_loader, tokenizer, device, output_dir, config):\n",
        "    # train\n",
        "    model.eval()\n",
        "\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = 'Testing:'\n",
        "\n",
        "    image_names = []\n",
        "    results = []\n",
        "    widths = []\n",
        "    heights = []\n",
        "    # user_ids = []\n",
        "    for i, (image, image_name, width, height) in enumerate(metric_logger.log_every(data_loader, 1, header)):\n",
        "        image = image.to(device, non_blocking=True)\n",
        "        # user_id = user_id.to(device, non_blocking=True)\n",
        "\n",
        "        coord = model.inference(image)\n",
        "        coord = coord.cpu().numpy().tolist()\n",
        "\n",
        "        width = width.numpy().tolist()\n",
        "        height = height.numpy().tolist()\n",
        "\n",
        "        # user_id = user_id.cpu().numpy().tolist()\n",
        "\n",
        "        image_names.extend(image_name)\n",
        "        results.extend(coord)\n",
        "        widths.extend(width)\n",
        "        heights.extend(height)\n",
        "        # user_ids.extend(user_id)\n",
        "\n",
        "    with open(os.path.join(output_dir, 'predicted_result.csv'), 'w') as wfile:\n",
        "        writer = csv.writer(wfile)\n",
        "        writer.writerow([\"image\", \"width\", \"height\", \"x\", \"y\", \"timestamp\"])\n",
        "\n",
        "        for image, width, height, coord in zip(image_names, widths, heights, results):\n",
        "\n",
        "            for row in coord:\n",
        "                x = row[0] * width\n",
        "                y = row[1] * height\n",
        "                t = row[2]\n",
        "                # username = data_loader.dataset.id2user[user_id]\n",
        "                writer.writerow([image, width, height,\n",
        "                                x, y, t])\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGtJPjU8stOh"
      },
      "outputs": [],
      "source": [
        "def main(args, config):\n",
        "    utils.init_distributed_mode(args)\n",
        "\n",
        "    device = torch.device(args.device)\n",
        "\n",
        "    # fix the seed for reproducibility\n",
        "    seed = args.seed + utils.get_rank()\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    #### Dataset ####\n",
        "    print(\"Creating dataset\")\n",
        "    datasets = [create_dataset('inference', config)]\n",
        "\n",
        "    if args.distributed:\n",
        "        num_tasks = utils.get_world_size()\n",
        "        global_rank = utils.get_rank()\n",
        "        samplers = create_sampler(datasets, [True], num_tasks, global_rank)\n",
        "    else:\n",
        "        samplers = [None]\n",
        "\n",
        "    data_loader = create_loader(datasets,\n",
        "                                samplers,\n",
        "                                batch_size=[config['batch_size_test']],\n",
        "                                num_workers=[32],\n",
        "                                is_trains=[False],\n",
        "                                collate_fns=[None])[0]\n",
        "\n",
        "    # tokenizer = BertTokenizer.from_pretrained(args.text_encoder)\n",
        "    tokenizer = None\n",
        "\n",
        "    #### Model ####\n",
        "    print(\"Creating model\")\n",
        "    model = TrackingTransformer(config=config, init_deit=False)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    if args.checkpoint:\n",
        "        checkpoint = torch.load(args.checkpoint, map_location='cpu')\n",
        "        state_dict = checkpoint['model']\n",
        "\n",
        "        msg = model.load_state_dict(state_dict)\n",
        "        print('load checkpoint from %s' % args.checkpoint)\n",
        "        print(msg)\n",
        "\n",
        "    model_without_ddp = model\n",
        "\n",
        "    print(\"Start testing\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    test(model, data_loader, tokenizer, device, args.output_dir, config)\n",
        "\n",
        "    dist.barrier()\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "    print('Testing time {}'.format(total_time_str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXfTMtBDstOh"
      },
      "outputs": [],
      "source": [
        "class ARGS:\n",
        "    config = './configs/Tracking.yaml'\n",
        "    checkpoint = './weights/checkpoint_19.pth'\n",
        "    resume = False\n",
        "    output_dir = 'output/tracking_eval'\n",
        "    text_encoder = 'bert-base-uncased'\n",
        "    device ='cuda'\n",
        "    seed = 42\n",
        "    world_size = 1\n",
        "    dist_url = 'env://'\n",
        "    distributed = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQTLur4YstOh"
      },
      "outputs": [],
      "source": [
        "args = ARGS()\n",
        "config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)\n",
        "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
        "yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))\n",
        "main(args, config)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}