{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EyeFormer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "!pip install ruamel.yaml\n",
    "import ruamel_yaml as yaml\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone Eyeformer & Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/YueJiang-nj/EyeFormer-UIST2024.git\n",
    "!pip install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0\n",
    "!pip install transformers==4.8.1 timm==0.4.9 \n",
    "!pip install opencv-python==4.5.3.56 Pillow einops multimatch-gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd EyeFormer-UIST2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_tracking import TrackingTransformer\n",
    "from models.vit import interpolate_pos_embed\n",
    "\n",
    "import utils\n",
    "from dataset import create_dataset, create_sampler, create_loader\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, tokenizer, device, output_dir, config):\n",
    "    # train\n",
    "    model.eval()\n",
    "\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Testing:'\n",
    "\n",
    "    image_names = []\n",
    "    results = []\n",
    "    widths = []\n",
    "    heights = []\n",
    "    # user_ids = []\n",
    "    for i, (image, image_name, width, height) in enumerate(metric_logger.log_every(data_loader, 1, header)):\n",
    "        image = image.to(device, non_blocking=True)\n",
    "        # user_id = user_id.to(device, non_blocking=True)\n",
    "\n",
    "        coord = model.inference(image)\n",
    "        coord = coord.cpu().numpy().tolist()\n",
    "\n",
    "        width = width.numpy().tolist()\n",
    "        height = height.numpy().tolist()\n",
    "\n",
    "        # user_id = user_id.cpu().numpy().tolist()\n",
    "\n",
    "        image_names.extend(image_name)\n",
    "        results.extend(coord)\n",
    "        widths.extend(width)\n",
    "        heights.extend(height)\n",
    "        # user_ids.extend(user_id)\n",
    "\n",
    "    with open(os.path.join(output_dir, 'predicted_result.csv'), 'w') as wfile:\n",
    "        writer = csv.writer(wfile)\n",
    "        writer.writerow([\"image\", \"width\", \"height\", \"x\", \"y\", \"timestamp\"])\n",
    "\n",
    "        for image, width, height, coord in zip(image_names, widths, heights, results):\n",
    "\n",
    "            for row in coord:\n",
    "                x = row[0] * width\n",
    "                y = row[1] * height\n",
    "                t = row[2]\n",
    "                # username = data_loader.dataset.id2user[user_id]\n",
    "                writer.writerow([image, width, height,\n",
    "                                x, y, t])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args, config):\n",
    "    utils.init_distributed_mode(args)\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    # fix the seed for reproducibility\n",
    "    seed = args.seed + utils.get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    #### Dataset ####\n",
    "    print(\"Creating dataset\")\n",
    "    datasets = [create_dataset('inference', config)]\n",
    "\n",
    "    if args.distributed:\n",
    "        num_tasks = utils.get_world_size()\n",
    "        global_rank = utils.get_rank()\n",
    "        samplers = create_sampler(datasets, [True], num_tasks, global_rank)\n",
    "    else:\n",
    "        samplers = [None]\n",
    "\n",
    "    data_loader = create_loader(datasets, \n",
    "                                samplers, \n",
    "                                batch_size=[config['batch_size_test']], \n",
    "                                num_workers=[32], \n",
    "                                is_trains=[False],\n",
    "                                collate_fns=[None])[0]\n",
    "\n",
    "    # tokenizer = BertTokenizer.from_pretrained(args.text_encoder)\n",
    "    tokenizer = None\n",
    "\n",
    "    #### Model ####\n",
    "    print(\"Creating model\")\n",
    "    model = TrackingTransformer(config=config, init_deit=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    if args.checkpoint:\n",
    "        checkpoint = torch.load(args.checkpoint, map_location='cpu')\n",
    "        state_dict = checkpoint['model']\n",
    "\n",
    "        msg = model.load_state_dict(state_dict)\n",
    "        print('load checkpoint from %s' % args.checkpoint)\n",
    "        print(msg)\n",
    "\n",
    "    model_without_ddp = model\n",
    "\n",
    "    print(\"Start testing\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    test(model, data_loader, tokenizer, device, args.output_dir, config)\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Testing time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    config = './configs/Tracking.yaml'\n",
    "    checkpoint = './weights/checkpoint_19.pth'\n",
    "    resume = False\n",
    "    output_dir = 'output/tracking_eval'\n",
    "    text_encoder = 'bert-base-uncased'\n",
    "    device ='cuda'\n",
    "    seed = 42\n",
    "    world_size = 1\n",
    "    dist_url = 'env://'\n",
    "    distributed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS()\n",
    "config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)\n",
    "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))\n",
    "main(args, config)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
