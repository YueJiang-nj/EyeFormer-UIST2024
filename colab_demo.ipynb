{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EyeFormer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pexpect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip install -Uqq ruamel.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mruamel_yaml\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/utils/_process_posix.py:125\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msystem\u001b[39m(\u001b[38;5;28mself\u001b[39m, cmd):\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute a command in a subshell.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    int : child's exitstatus\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpexpect\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Get likely encoding for the output.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     enc \u001b[38;5;241m=\u001b[39m DEFAULT_ENCODING\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pexpect'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone Eyeformer & Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/YueJiang-nj/EyeFormer-UIST2024.git\n",
    "!pip install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0\n",
    "!pip install transformers==4.8.1 timm==0.4.9 \n",
    "!pip install opencv-python==4.5.3.56 Pillow einops multimatch-gaze\n",
    "!pip install ruamel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd EyeFormer-UIST2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_tracking import TrackingTransformer\n",
    "from models.vit import interpolate_pos_embed\n",
    "\n",
    "import ruamel_yaml as yaml\n",
    "import utils\n",
    "from dataset import create_dataset, create_sampler, create_loader\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, tokenizer, device, output_dir, config):\n",
    "    # train\n",
    "    model.eval()\n",
    "\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Testing:'\n",
    "\n",
    "    image_names = []\n",
    "    results = []\n",
    "    widths = []\n",
    "    heights = []\n",
    "    # user_ids = []\n",
    "    for i, (image, image_name, width, height) in enumerate(metric_logger.log_every(data_loader, 1, header)):\n",
    "        image = image.to(device, non_blocking=True)\n",
    "        # user_id = user_id.to(device, non_blocking=True)\n",
    "\n",
    "        coord = model.inference(image)\n",
    "        coord = coord.cpu().numpy().tolist()\n",
    "\n",
    "        width = width.numpy().tolist()\n",
    "        height = height.numpy().tolist()\n",
    "\n",
    "        # user_id = user_id.cpu().numpy().tolist()\n",
    "\n",
    "        image_names.extend(image_name)\n",
    "        results.extend(coord)\n",
    "        widths.extend(width)\n",
    "        heights.extend(height)\n",
    "        # user_ids.extend(user_id)\n",
    "\n",
    "    with open(os.path.join(output_dir, 'predicted_result.csv'), 'w') as wfile:\n",
    "        writer = csv.writer(wfile)\n",
    "        writer.writerow([\"image\", \"width\", \"height\", \"x\", \"y\", \"timestamp\"])\n",
    "\n",
    "        for image, width, height, coord in zip(image_names, widths, heights, results):\n",
    "\n",
    "            for row in coord:\n",
    "                x = row[0] * width\n",
    "                y = row[1] * height\n",
    "                t = row[2]\n",
    "                # username = data_loader.dataset.id2user[user_id]\n",
    "                writer.writerow([image, width, height,\n",
    "                                x, y, t])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args, config):\n",
    "    utils.init_distributed_mode(args)\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    # fix the seed for reproducibility\n",
    "    seed = args.seed + utils.get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    #### Dataset ####\n",
    "    print(\"Creating dataset\")\n",
    "    datasets = [create_dataset('inference', config)]\n",
    "\n",
    "    if args.distributed:\n",
    "        num_tasks = utils.get_world_size()\n",
    "        global_rank = utils.get_rank()\n",
    "        samplers = create_sampler(datasets, [True], num_tasks, global_rank)\n",
    "    else:\n",
    "        samplers = [None]\n",
    "\n",
    "    data_loader = create_loader(datasets, \n",
    "                                samplers, \n",
    "                                batch_size=[config['batch_size_test']], \n",
    "                                num_workers=[32], \n",
    "                                is_trains=[False],\n",
    "                                collate_fns=[None])[0]\n",
    "\n",
    "    # tokenizer = BertTokenizer.from_pretrained(args.text_encoder)\n",
    "    tokenizer = None\n",
    "\n",
    "    #### Model ####\n",
    "    print(\"Creating model\")\n",
    "    model = TrackingTransformer(config=config, init_deit=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    if args.checkpoint:\n",
    "        checkpoint = torch.load(args.checkpoint, map_location='cpu')\n",
    "        state_dict = checkpoint['model']\n",
    "\n",
    "        msg = model.load_state_dict(state_dict)\n",
    "        print('load checkpoint from %s' % args.checkpoint)\n",
    "        print(msg)\n",
    "\n",
    "    model_without_ddp = model\n",
    "\n",
    "    print(\"Start testing\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    test(model, data_loader, tokenizer, device, args.output_dir, config)\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Testing time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    config = './configs/Tracking.yaml'\n",
    "    checkpoint = './weights/checkpoint_19.pth'\n",
    "    resume = False\n",
    "    output_dir = 'output/tracking_eval'\n",
    "    text_encoder = 'bert-base-uncased'\n",
    "    device ='cuda'\n",
    "    seed = 42\n",
    "    world_size = 1\n",
    "    dist_url = 'env://'\n",
    "    distributed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./weights/checkpoint_19.pth\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'yaml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m ARGS()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(args\u001b[38;5;241m.\u001b[39mcheckpoint)\n\u001b[0;32m----> 3\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(args\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m), Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[1;32m      4\u001b[0m Path(args\u001b[38;5;241m.\u001b[39moutput_dir)\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m yaml\u001b[38;5;241m.\u001b[39mdump(config, \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yaml' is not defined"
     ]
    }
   ],
   "source": [
    "args = ARGS()\n",
    "# print(args.checkpoint)\n",
    "config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)\n",
    "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))\n",
    "main(args, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
